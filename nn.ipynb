{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "import math\n",
    "import numbers\n",
    "\n",
    "import torchfcn\n",
    "\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cv_folds(img_root, gt_root, num_folds, random_state):\n",
    "    samples = []\n",
    "    folds = [list() for i in range(num_folds)]\n",
    "    lengths = [0]*num_folds\n",
    "    img_root = os.path.expanduser(img_root)\n",
    "    gt_root = os.path.expanduser(gt_root)\n",
    "    for f in sorted(os.listdir(img_root)):\n",
    "        if not os.path.isfile(os.path.join(img_root, f)) or not os.path.isfile(os.path.join(gt_root, f.rsplit(\".\", 1)[0] + \".png\")):\n",
    "            raise Exception(\"GT fehlt\")\n",
    "        samples.append((os.path.join(img_root, f), os.path.join(gt_root, f.rsplit(\".\", 1)[0] + \".png\")))\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(samples)\n",
    "    np.random.seed()\n",
    "\n",
    "    for s in samples:\n",
    "        idx = np.argmin(lengths)\n",
    "        folds[idx].append(s)\n",
    "        lengths[idx] += 1\n",
    "    return folds\n",
    "\n",
    "def load_sample(img_path, gt_path):\n",
    "    img = Image.open(img_path)\n",
    "    gt = Image.open(gt_path)\n",
    "    gt = np.array(gt)[:,:,2]\n",
    "    \n",
    "    #binary format\n",
    "    gt[gt == 0] = 2\n",
    "    gt[gt == 255] = 1\n",
    "\n",
    "    #hisdb format\n",
    "    gt[gt == 1] = 1\n",
    "    gt[(gt%8) == 0] = 1\n",
    "    gt[(gt%4) == 0] = 1\n",
    "    gt[(gt%2) == 0] = 0\n",
    "    gt = Image.fromarray(gt)\n",
    "    return img, gt\n",
    "\n",
    "\n",
    "class Annotations(Dataset):\n",
    "    class_names = np.array(['other', 'annotation'])\n",
    "    \n",
    "    def __init__(self, img_root, gt_root, loader=load_sample, num_folds=5, preprocess=None, random_state=None):\n",
    "        self.folds = make_cv_folds(img_root, gt_root, num_folds=num_folds, random_state=random_state)\n",
    "        self.img_root = img_root\n",
    "        self.num_folds = num_folds\n",
    "        self.preprocess = preprocess\n",
    "        self.loader = loader\n",
    "        self.is_training = True\n",
    "        self.load_split(num=0)\n",
    "\n",
    "    def train(self, val):\n",
    "        if val:\n",
    "            self.is_training = True\n",
    "            self.samples = self.train_samples\n",
    "        else:\n",
    "            self.is_training = False\n",
    "            self.samples = self.test_samples\n",
    "    \n",
    "    def load_split(self, num=0):\n",
    "        if len(self.folds) == 1:\n",
    "            self.train_samples = self.folds[0]\n",
    "            self.test_samples = self.folds[0]\n",
    "        else:\n",
    "            num = num%len(self.folds)\n",
    "            train_folds = list(range(0,num)) + list(range(num+1, len(self.folds)))\n",
    "            test_fold = num\n",
    "            self.train_samples = []\n",
    "            for i in train_folds:\n",
    "                self.train_samples.extend(self.folds[i])\n",
    "            self.test_samples = self.folds[num]\n",
    "        if self.is_training:\n",
    "            self.samples = self.train_samples\n",
    "        else:\n",
    "            self.samples = self.test_samples\n",
    "            \n",
    "    def untransform(self, img, gt):\n",
    "        img = img.numpy()\n",
    "        img = img.transpose(1, 2, 0)\n",
    "        img = img.astype(np.uint8)\n",
    "        img = img[:, :, ::-1]\n",
    "        gt = gt.numpy()\n",
    "        return img, gt\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path, gt_path = self.samples[index]\n",
    "        img, gt = self.loader(img_path, gt_path)\n",
    "        if self.preprocess is not None:\n",
    "            state = time.time()\n",
    "            img = self.preprocess(img, random_state=state)\n",
    "            gt = self.preprocess(gt, random_state=state)\n",
    "        \n",
    "        img = np.array(img, dtype=np.uint8)\n",
    "        img = img[:, :, ::-1]  # RGB -> BGR\n",
    "        img = img.astype(np.float64)\n",
    "        img = img.transpose(2, 0, 1)\n",
    "        img = torch.from_numpy(img).float()\n",
    "        gt = np.array(gt, dtype=np.int32)\n",
    "        gt = torch.from_numpy(gt).long()\n",
    "        return img, gt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __repr__(self):\n",
    "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "        fmt_str += '    Number of training samples: {}\\n'.format(len(self.train_samples))\n",
    "        fmt_str += '    Number of testing samples: {}\\n'.format(len(self.test_samples))\n",
    "        return fmt_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CenterCrop(object):\n",
    "    \"\"\"Crops the given PIL Image at the center.\n",
    "    Args:\n",
    "        size (sequence or int): Desired output size of the crop. If size is an\n",
    "            int instead of sequence like (h, w), a square crop (size, size) is\n",
    "            made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size):\n",
    "        if isinstance(size, numbers.Number):\n",
    "            self.size = (int(size), int(size))\n",
    "        else:\n",
    "            self.size = size\n",
    "\n",
    "    def __call__(self, img, random_state=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be cropped.\n",
    "        Returns:\n",
    "            PIL Image: Cropped image.\n",
    "        \"\"\"\n",
    "        return transforms.functional.center_crop(img, self.size)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(size={0})'.format(self.size)\n",
    "\n",
    "\n",
    "class RandomResizedCrop(object):\n",
    "    \"\"\"Crop the given PIL Image to random size and aspect ratio.\n",
    "    A crop of random size (default: of 0.08 to 1.0) of the original size and a random\n",
    "    aspect ratio (default: of 3/4 to 4/3) of the original aspect ratio is made. This crop\n",
    "    is finally resized to given size.\n",
    "    This is popularly used to train the Inception networks.\n",
    "    Args:\n",
    "        size: expected output size of each edge\n",
    "        scale: range of size of the origin size cropped\n",
    "        ratio: range of aspect ratio of the origin aspect ratio cropped\n",
    "        interpolation: Default: PIL.Image.BILINEAR\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, scale=(0.08, 1.0), ratio=(3. / 4., 4. / 3.), interpolation=Image.NEAREST):\n",
    "        self.size = (size, size)\n",
    "        self.interpolation = interpolation\n",
    "        self.scale = scale\n",
    "        self.ratio = ratio\n",
    "\n",
    "    @staticmethod\n",
    "    def get_params(img, scale, ratio, random_state=None):\n",
    "        \"\"\"Get parameters for ``crop`` for a random sized crop.\n",
    "        Args:\n",
    "            img (PIL Image): Image to be cropped.\n",
    "            scale (tuple): range of size of the origin size cropped\n",
    "            ratio (tuple): range of aspect ratio of the origin aspect ratio cropped\n",
    "        Returns:\n",
    "            tuple: params (i, j, h, w) to be passed to ``crop`` for a random\n",
    "                sized crop.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        random.seed(random_state)\n",
    "        for attempt in range(10):\n",
    "            area = img.size[0] * img.size[1]\n",
    "            target_area = random.uniform(*scale) * area\n",
    "            aspect_ratio = random.uniform(*ratio)\n",
    "\n",
    "            w = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "            h = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "\n",
    "            if random.random() < 0.5:\n",
    "                w, h = h, w\n",
    "\n",
    "            if w <= img.size[0] and h <= img.size[1]:\n",
    "                i = random.randint(0, img.size[1] - h)\n",
    "                j = random.randint(0, img.size[0] - w)\n",
    "                return i, j, h, w\n",
    "\n",
    "        # Fallback\n",
    "        w = min(img.size[0], img.size[1])\n",
    "        i = (img.size[1] - w) // 2\n",
    "        j = (img.size[0] - w) // 2\n",
    "        return i, j, w, w\n",
    "\n",
    "    def __call__(self, img, random_state=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be cropped and resized.\n",
    "        Returns:\n",
    "            PIL Image: Randomly cropped and resized image.\n",
    "        \"\"\"\n",
    "        i, j, h, w = self.get_params(img, self.scale, self.ratio, random_state=random_state)\n",
    "        return transforms.functional.resized_crop(img, i, j, h, w, self.size, self.interpolation)\n",
    "\n",
    "    def __repr__(self):\n",
    "        interpolate_str = _pil_interpolation_to_str[self.interpolation]\n",
    "        format_string = self.__class__.__name__ + '(size={0}'.format(self.size)\n",
    "        format_string += ', scale={0}'.format(round(self.scale, 4))\n",
    "        format_string += ', ratio={0}'.format(round(self.ratio, 4))\n",
    "        format_string += ', interpolation={0})'.format(interpolate_str)\n",
    "        return format_string\n",
    "\n",
    "    \n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop the given PIL Image at a random location.\n",
    "    Args:\n",
    "        size (sequence or int): Desired output size of the crop. If size is an\n",
    "            int instead of sequence like (h, w), a square crop (size, size) is\n",
    "            made.\n",
    "        padding (int or sequence, optional): Optional padding on each border\n",
    "            of the image. Default is 0, i.e no padding. If a sequence of length\n",
    "            4 is provided, it is used to pad left, top, right, bottom borders\n",
    "            respectively.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, padding=0):\n",
    "        if isinstance(size, numbers.Number):\n",
    "            self.size = (int(size), int(size))\n",
    "        else:\n",
    "            self.size = size\n",
    "        self.padding = padding\n",
    "\n",
    "    @staticmethod\n",
    "    def get_params(img, output_size, random_state=None):\n",
    "        \"\"\"Get parameters for ``crop`` for a random crop.\n",
    "        Args:\n",
    "            img (PIL Image): Image to be cropped.\n",
    "            output_size (tuple): Expected output size of the crop.\n",
    "        Returns:\n",
    "            tuple: params (i, j, h, w) to be passed to ``crop`` for random crop.\n",
    "        \"\"\"\n",
    "        random.seed(random_state)\n",
    "        \n",
    "        w, h = img.size\n",
    "        th, tw = output_size\n",
    "        if w == tw and h == th:\n",
    "            return 0, 0, h, w\n",
    "\n",
    "        i = random.randint(0, h - th)\n",
    "        j = random.randint(0, w - tw)\n",
    "        return i, j, th, tw\n",
    "\n",
    "    def __call__(self, img, random_state=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be cropped.\n",
    "        Returns:\n",
    "            PIL Image: Cropped image.\n",
    "        \"\"\"\n",
    "        if self.padding > 0:\n",
    "            img = F.pad(img, self.padding)\n",
    "\n",
    "        i, j, h, w = self.get_params(img, self.size, random_state=random_state)\n",
    "\n",
    "        return transforms.functional.crop(img, i, j, h, w)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(size={0}, padding={1})'.format(self.size, self.padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_train = RandomResizedCrop(size=1024)\n",
    "preprocess_test = RandomResizedCrop(size=1024)\n",
    "\n",
    "\n",
    "trainset = Annotations(img_root='public_shared/input/',\n",
    "                      gt_root='public_shared/new_bin',\n",
    "                      preprocess=preprocess_train,\n",
    "                      num_folds=1)\n",
    "\n",
    "testset = Annotations(img_root='test/input/',\n",
    "                      gt_root='test/new_bin/',\n",
    "                      preprocess=preprocess_test,\n",
    "                      num_folds=1)\n",
    "\n",
    "testset.train(False)\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=1, shuffle=True, num_workers=8, drop_last=True)\n",
    "test_loader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=8, drop_last=True)\n",
    "\n",
    "\n",
    "dat = trainset[0]\n",
    "img = dat[0].numpy().transpose(1,2,0)\n",
    "gt = dat[1].numpy()\n",
    "\n",
    "print(img.shape)\n",
    "print(gt.shape)\n",
    "\n",
    "plt.imshow(img.squeeze())\n",
    "plt.show()\n",
    "plt.imshow(gt.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log_dir = \"log-mg3/\"\n",
    "\n",
    "\n",
    "def get_parameters(model, bias=False):\n",
    "    import torch.nn as nn\n",
    "    modules_skipped = (\n",
    "        nn.ReLU,\n",
    "        nn.MaxPool2d,\n",
    "        nn.Dropout2d,\n",
    "        nn.Sequential,\n",
    "        torchfcn.models.FCN8s,\n",
    "    )\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            if bias:\n",
    "                yield m.bias\n",
    "            else:\n",
    "                yield m.weight\n",
    "        elif isinstance(m, nn.ConvTranspose2d):\n",
    "            # weight is frozen because it is just a bilinear upsampling\n",
    "            if bias:\n",
    "                assert m.bias is None\n",
    "        elif isinstance(m, modules_skipped):\n",
    "            continue\n",
    "        else:\n",
    "            raise ValueError('Unexpected module: %s' % str(m))\n",
    "\n",
    "\n",
    "\n",
    "configurations = {\n",
    "    # same configuration as original work\n",
    "    # https://github.com/shelhamer/fcn.berkeleyvision.org\n",
    "    1: dict(\n",
    "        max_iteration=200000,\n",
    "        lr=1.0e-10,\n",
    "        momentum=0.99,\n",
    "        weight_decay=0.0005,\n",
    "        interval_validate=4000,\n",
    "    )\n",
    "}\n",
    "\n",
    "cfg = configurations[1]\n",
    "out = log_dir\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(1337)\n",
    "\n",
    "resume = \"\"\n",
    "\n",
    "model = torchfcn.models.FCN8sAtOnce(n_class=2)\n",
    "start_epoch = 0\n",
    "start_iteration = 0\n",
    "if resume:\n",
    "    checkpoint = torch.load(resume)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    start_iteration = checkpoint['iteration']\n",
    "else:\n",
    "    vgg16 = torchfcn.models.VGG16(pretrained=True)\n",
    "    model.copy_params_from_vgg16(vgg16)\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    [\n",
    "        {'params': get_parameters(model, bias=False)},\n",
    "        {'params': get_parameters(model, bias=True),\n",
    "         'lr': cfg['lr'] * 2, 'weight_decay': 0},\n",
    "    ],\n",
    "    lr=cfg['lr'],\n",
    "    momentum=cfg['momentum'],\n",
    "    weight_decay=cfg['weight_decay'])\n",
    "if resume:\n",
    "    optimizer.load_state_dict(checkpoint['optim_state_dict'])\n",
    "\n",
    "trainer = torchfcn.Trainer(\n",
    "    cuda=cuda,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    out=out,\n",
    "    max_iter=cfg['max_iteration'],\n",
    "    interval_validate=cfg.get('interval_validate', len(train_loader)),\n",
    ")\n",
    "trainer.epoch = start_epoch\n",
    "trainer.iteration = start_iteration\n",
    "# trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    processes = []\n",
    "    mius = []\n",
    "    \n",
    "    for index in tqdm(range(len(data_loader.dataset))):\n",
    "        _, gt_path = data_loader.dataset.samples[index]\n",
    "        image, _ = data_loader.dataset[index]\n",
    "        image = image.numpy()\n",
    "        image.shape = (1, image.shape[0], image.shape[1], image.shape[2])\n",
    "        prediction = np.zeros((image.shape[2], image.shape[3], 3), dtype=np.uint8)\n",
    "        div_arr = np.zeros((image.shape[2], image.shape[3]), dtype=np.uint8)\n",
    "        \n",
    "        offsets_vertical = list(range(0, image.shape[2], 256))\n",
    "        offsets_horizontal = list(range(0, image.shape[3], 256))\n",
    "        \n",
    "        for v in offsets_vertical:\n",
    "            for h in offsets_horizontal:\n",
    "                data = image[:, :, v:v+1024, h:h+1024]\n",
    "                data = torch.from_numpy(data)\n",
    "                data = data.cuda()\n",
    "                data = Variable(data, volatile=True)\n",
    "                score = model(data)\n",
    "                lbl_pred = score.data.max(1)[1].cpu().numpy()[:, :, :]\n",
    "                lbl_pred[lbl_pred == 0] = 2\n",
    "                prediction[v:v+1024, h:h+1024, 2] += lbl_pred.astype(np.uint8).squeeze()\n",
    "                div_arr[v:v+1024, h:h+1024] += 1\n",
    "    \n",
    "        prediction[:,:,2] = np.round(prediction[:,:,2]/div_arr)\n",
    "        \n",
    "        im = Image.fromarray(prediction)\n",
    "        prediction_path = os.path.join(log_dir, \"prediction-private\")\n",
    "        if not os.path.isdir(prediction_path):\n",
    "            os.makedirs(prediction_path)\n",
    "        prediction_filename = os.path.join(prediction_path, os.path.basename(gt_path))\n",
    "        im.save(prediction_filename)\n",
    "        \n",
    "        processes.append(subprocess.Popen([\"java\", \"-jar\", \"DIVA_Layout_Analysis_Evaluator/out/artifacts/LayoutAnalysisEvaluator.jar\", \"-p\", prediction_filename, \"-gt\", gt_path], stdout=subprocess.PIPE))\n",
    "\n",
    "    for p in processes:\n",
    "        miu = float(p.communicate()[0].splitlines()[0].split()[-1])\n",
    "        mius.append(miu)\n",
    "    \n",
    "    print(mius)\n",
    "    print(\"average:\", np.mean(mius))\n",
    "    return np.mean(mius)\n",
    "\n",
    "\n",
    "testset = Annotations(img_root='test/input/',\n",
    "                      gt_root='test/new_gt/',\n",
    "                      preprocess=None,\n",
    "                      num_folds=1)\n",
    "\n",
    "testset.train(False)\n",
    "\n",
    "test_loader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=8, drop_last=True)\n",
    "\n",
    "evaluate_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
